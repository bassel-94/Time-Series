---
title: "Homework"
author: "Bassel MASRI & Andrei CHIRITA"
date: "1/21/2021"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r, include = FALSE, warning=FALSE, echo=FALSE}
#https://fred.stlouisfed.org/series/CPIAUCNS
#https://fred.stlouisfed.org/series/TRFVOLUSM227NFWA
#-- clean environment and load libraries
rm(list=ls())
if(!require(MTS)) install.packages("MTS")
library(ggplot2)
library(tidyverse)
library(zoo)
library(tseries)
```
\newpage
\setcounter{tocdepth}{2}
\pagenumbering{arabic}
\tableofcontents
\newpage
# Exercise 1

The purpose of this exercise is to simulate a path of length $T = 100$ from the VAR(1) model : 

$$
X_t = A_n X_{t-1} + \epsilon_t
$$

Where $\epsilon_t$ is a standard multivariate gaussian white noise.

To demonstrate the parameters of the problem, we will take the simple example of $n=2$, that is a stationary bivariate VAR(1) model which has the following form :

$$
\left(\begin{array}{c} 
X_{1t}\\ 
X_{2t}
\end{array}\right)
= 
\left(\begin{array}{c} 
c_1\\ 
c_2
\end{array}\right)
+
\left(\begin{array}{cc} 
A_{1,1} & A_{1,2}\\ 
A_{2,1} & A_{2,2}
\end{array}\right)
\times
\left(\begin{array}{c} 
X_{1t-1} \\ 
X_{2t-1}
\end{array}\right)
+
\left(\begin{array}{c} 
\epsilon_{1t} \\ 
\epsilon_{2t}
\end{array}\right)
$$ 
In our case, we have the following parameters; $A_{n}(i,i) = \frac{1}{2}$, $A_{n}(i,i+1) = \frac{1}{5}$, and $A_{n}(i,j) = 0$. For the specific case of $n=2$, this enables us to rewrite the model that we need to estimate as follows:

$$
\left(\begin{array}{cc} 
X_{1t}\\ 
X_{2t}
\end{array}\right)
= 
\left(\begin{array}{cc} 
c_1\\ 
c_2
\end{array}\right)
+
\left(\begin{array}{cc} 
0.5 & 0.2\\ 
0 & 0.5
\end{array}\right)
\times
\left(\begin{array}{cc} 
X_{1t-1} \\ 
X_{2t-1}
\end{array}\right)
+
\left(\begin{array}{cc} 
\epsilon_{1t} \\ 
\epsilon_{2t}
\end{array}\right)
$$ 

The steps are :

* Define the parameters of the problem
* Generate VAR(1) model
* Estimate VAR(1) model
* Calculate error on the estimated VAR(1) model.

We will compute the above steps using the following code chunk:

```{r}
#-- define function that simulates var models
simulate_var = function(n, T) {
  
  #-- set seed for reproducible results
  set.seed(123)
  error=rep(0, length(n))
  
  for (l in seq_along(n)){
    p=n[l]
    A=0.5*diag(p)
    X=matrix(0,nrow=p ,ncol=T)
    
    for (i in 1:(p-1)){
      A[i,i+1]=0.2
    }
    
    #-- Generate a VAR model of dimension n[l] with T obs
    for (j in 2:T){
      X[,j]=A%*%X[,(j-1)]+t(t(rnorm(p)))
    }
    
    #-- Estimate a VAR model of dimension n[l] from T obs
    Estim=VAR(t(X),1)
    A_hat=Estim$Phi
    
    #-- Study the estimation error
    B=A_hat-A
    error[l]=sqrt(max(abs(eigen(t(B)%*%B)$values)))
  }
  return(error)
}
```

```{r, warning=FALSE, include=FALSE}
#-- test for T=c(100,200,1000)
n = c(2,5,10,20)
error_T100 = simulate_var(n,100)
error_T500 = simulate_var(n,200)
error_T1000 = simulate_var(n,1000)
```

```{r, include=FALSE, echo = FALSE}
#-- group results in a data frame and produce a column of indices to plot against
df = data.frame("T_100" = error_T100, 
                "T_500" = error_T500, 
                "T_1000" = error_T1000) %>% 
  rowid_to_column() %>%
  gather(key = "T_values", value = "Errors", -rowid)
```

We then compute the error $n=\{2,5,10,20\}$ for the following path lengths; $T=\{100,500,1000\}$ and we get the following plot: 

```{r, echo=FALSE,fig.align='center', fig.width=4, fig.height=3, fig.cap="The variation of error as a function of simulation length T and number of covariates n"}
#-- plot results
ggplot(df, aes(x=rowid, y = Errors, color = T_values)) + 
  geom_line() + geom_point() + theme_bw() + 
  ggtitle("Errors as a function of T and n") + 
  scale_x_discrete(name ="Values of n", limits=c("2","5","10", "20")) +
  theme(plot.title = element_text(size = 10, face = "bold", hjust = 0.6), 
        legend.title = element_text(size = 8, face = "bold"),
        legend.text = element_text(size = 6),
        axis.text=element_text(size=6),
        axis.title=element_text(size=8,face="bold"))
```

Upon examining the plot of the squared $\ell_2$ error term, we notice a consistent increase in the error with respect to the numbers of covariates. When n becomes large, the error value increases. This is expected because the more covariates we have to estimate, the more error we introduce in the model. 

As for the path length $T$, we notice that the smallest error values are for path $T=1000$. This is due to the fact that we have more observations in the time series that enables us to estimate the coefficients more accuratly. To put differently, with more *information* to estimate the model's parameters, we are able to achieve more accurate results.

\newpage

# Exercise 2 

## Goal of the Analysis

Our analysis has as purpose to find out what are the main influences on gasoline prices. More specifically we try to put the evolution of gasoline prices in the last 26 year in the context of 2 indicators: the vehicle related mobility and crude oil prices.

In order to do that we use monthly data from the United States. We chose monthly data because it is easier to interpret in economically. We decided on using data from the United States because the U.S.A. is the largest economy in the world and one of the largest crude oil producers and special rules around the export of oil products. Thus we can consider that the U.S. has an oil economy that is both U.S.A.-centered and at the same time representative of worldwide trends in oil and gasoline prices. 

## Description of the data

During our analysis we use 5 time series, 4 related to the evolution of the prices and consumption and gasoline and diesel in the United States of America and 1 general economic indicator (The CPI). The series are:

* U.S. All Grades All Formulations Retail Gasoline Prices (referred bellow as gasoline prices): It is a general value of gasoline prices in the United States, the series is downloaded from the U.S. Energy Information Administration (EIA). The values of this series are expressed in Dollars per Gallon.

* U.S. No 2 Diesel Retail Prices (referred bellow as diesel prices): It is a general value of diesel prices in the United States, the series is downloaded from EIA. The values of the series are expressed in Dollars per Gallon.

* Cushing, OK WTI Spot Price FOB (referred bellow as crude oil price): It is a general value of the price of crude oil in the United States, the series is downloaded from EIA and its values are expressed in Dollars per Barrel.

* Vehicle Miles Traveled: It represents a measure of the vehicle-related mobility in the United States, the series is downloaded from the site of the Federal Reserve Bank of St. Louis. The unit of measurement is: millions of miles.

* Consumer Price Index for All Urban Consumers: All Items in U.S. City Average: This is a measure of CPI, the downloaded data is an index with the base in the early 1980's. We needed this series because we are dealing with prices that need to be adjusted with inflation in order to allow for comparisons between distant time periods. This series was downloaded from the site of the Federal Reserve Bank of the United States.

## Loading and Preparing the Data

On the first step we had to load the data from the csv files it was stored on. Then we made sure that the dates are expressed in a format that was comprehensible for R.
On this step we also re-expressed the CPI in order for it's base to be the month of April of 1994. The change of basis was done by dividing all the values in the CPI series with the value for April 1994.
Next we "assembled the data sets" and extracted the year for plotting, we also reshaped the data in a long format, again for plotting purposes.

```{r}
data<-read.csv("serie completa.csv",sep=",",header=TRUE)
dates <- seq(ISOdate(1994,4,1), by = "month", length.out = 321)
data$Date<-dates
data<-data[-321,]
CPI<-read.csv("CPIAUCNS.csv",sep=",",header=TRUE)
CPI<-CPI[-321,]
Road_travel<-read.csv("TRFVOLUSM227NFWA.csv")
```

```{r}
CPI1<-data.frame(DATE=CPI[,1],CPI[,2]/CPI[1,2])
```

```{r}
data<-data.frame(data,Miles_Travelled=Road_travel[,2])
```

```{r}
data2<-reshape(data, 
        direction = "long",
        varying = list(names(data)[2:5]),
        v.names = "Value",
        idvar = c("Date"),
        timevar = "Type",
        times = c("Diesel","Gasoline","Crude","Miles"))
years=as.numeric(format(as.Date(data2$Date, format="%d/%m/%Y"),"%Y"))
years<-substr(years,3,4)
years<-factor(years,levels = c("94","95","96","97","98","99","00",
                               "01","02","03","04","05","06","07","08","09",
                               "10","11","12","13","14","15","16","17","18","19","20"))
data2<-data.frame(data2,year=years)
```

## Yearly and Monthly Evolution of the Series

### Yearly Evolution

The first step of our exploratory data analysis of the time series at hand is to produce a plot showing the evolution of Crude oil prices as well as the miles traveled over time.  

```{r, warning=FALSE, echo=FALSE,fig.align="center", fig.width=8, fig.height=4, fig.cap="Yearly evolution of crude oil prices and miles traveled"}
library(gridExtra)
library(scales)
p1 = ggplot(data2[data2$Type=="Crude",])+
  aes(x=as.factor(year),y=Value)+
  geom_boxplot()+
  stat_summary(fun=median, geom="smooth", aes(group=1))+
  ggtitle("Yearly Evolution of Crude Oil Prices")+
  xlab("Year")+
  ylab("Price in dolars") + theme_bw() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

p2 = ggplot(data2[data2$Type=="Miles",])+
  aes(x=as.factor(year),y=Value)+
  geom_boxplot()+
  stat_summary(fun=median, geom="smooth", aes(group=1))+
  ggtitle("Yearly Evolution of Miles Travelled per Month")+
  xlab("Year")+
  ylab("Miles") + theme_bw() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

grid.arrange(p1,p2, ncol = 2)
```

The plots above show the values for each year as boxplots with the blue line uniting the medians of each year. For the crude oil prices we can observe that prices increased steadily from 2003 to 2008 when they had a sudden drop due to the financial and economic crisis of that year. Recovery was fast and from 2011 to 2014 prices remained on a plateau just bellow 100$ per barrel. In 2015 prices declined again, but this time the recovery was sower and was also interrupted by the COVID-19 pandemic. From the point of view of variability three years stand out 2007, 2008 and 2009, this are years when the price grew and declined very rapidly. The number of miles traveled per month had a similar variability each year and most years also have an extreme low-value. The series has an ascending trend that was "smoothed" by the crisis of 2008 and somewhat reversed (probably temporarily) by the Covid-19 pandemic.

### Monthly Evolution

In the following plots we can observe the monthly evolution of the data sets, we had to plot them separately because of the different units of measurement. The evolution of diesel and gasoline prices was very similar and it basically followed he same movement trajectory as that of the crude oil.

On the plot of the prices of crude oil  we added a blue line representing a moving average with basis 12. It has a similar trajectory to the non-smoothed series. 
For the traveled miles data we can observe a clear seasonality with travel declining around February, in this case smoothing using moving averages has a greater impact allowing us to see the trend.

```{r, warning=FALSE, echo=FALSE, fig.width=12, fig.height=4, fig.cap="Monthly evolution of crude oil prices and miles traveled"}

p1 = ggplot(data2[data2$Type=="Diesel"|data2$Type=="Gasoline",])+
  aes(x=Date,y=Value,colour=Type)+
  geom_line()+
  ggtitle("Evolution of Diesel and Gasoline prices")+
  xlab("Year")+
  ylab("Price in dolars (1994)") + theme_bw()

p2 = ggplot(data2[data2$Type=="Crude",])+
  aes(x=Date,y=Value,colour=Type)+
  geom_line()+
  ggtitle("Crude Oil Prices")+
  xlab("Year")+
  ylab("Price in dolars (1994)")+
  geom_line(aes(y=rollmean(Value, 12, na.pad=TRUE)),colour="blue") + theme_bw()

p3 = ggplot(data2[data2$Type=="Miles",])+
  aes(x=Date,y=Value,colour=Type)+
  geom_line()+
  geom_line(aes(y=rollmean(Value, 12, na.pad=TRUE)),colour="blue") + theme_bw() +
  ggtitle("Miles Travelled per Month")+
  xlab("Year")+
  ylab("Miles")

grid.arrange(p1,p2,p3, ncol = 3)
```

## Adjusting for inflation

The next step of our analysis would be to adjust the series for inflation. This step is essential in order to make the prices of different time periods comparable as inflation can induce a trend where there is actually none. The adjustment was done by dividing the price time series by the index of the CPI corresponding to each month. The basis for the adjustment was the month of April of 1994.

```{r, include=FALSE, warning=FALSE, echo=FALSE}
data3<-data.frame(Date=data$Date,
                 Diesel=data$U.S..No.2.Diesel.Retail.Prices..Dollars.per.Gallon./CPI1[,2],
                 Gasoline=data$U.S..All.Grades.All.Formulations.Retail.Gasoline.Prices..Dollars.per.Gallon./CPI1[,2],
                 Crude=data$Cushing..OK.WTI.Spot.Price.FOB..Dollars.per.Barrel./CPI1[,2],
                 Miles=data$Miles_Travelled)
data3
```

The yearly evolution of adjusted for inflation crude prices was similar to the one unadjusted but the prices in the last years of the series are lower (and thus closer to the ones of the first years). Thus we can observe on this serie that cruse prices went from just bellow 25 doars in the 1990's to basically the same level today with much higher prices in between.

```{r, echo=FALSE, warning=FALSE, fig.width=6, fig.height=4, fig.cap="Yearly evolution of crude oil prices after adjustmenet for inflation"}
data4<-reshape(data3, 
        direction = "long",
        varying = list(names(data3)[2:5]),
        v.names = "Value",
        idvar = c("Date"),
        timevar = "Type",
        times = c("Diesel","Gasoline","Crude","Miles"))

data4<-data.frame(data4,year=as.numeric(format(as.Date(data4$Date, format="%d/%m/%Y"),"%Y")))

ggplot(data4[data4$Type=="Crude",])+
  aes(x=as.factor(year),y=Value)+
  geom_boxplot()+
  stat_summary(fun=median, geom="smooth", aes(group=1))+
  ggtitle("Yearly Evolution of Crude Oil Prices",subtitle = "Adjusted for inflation")+
  xlab("Year")+
  ylab("Price in dolars (1994)") + theme_bw() + 
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

Similarly, we show the evolution of monthly prices of Diesel and Gasoline prices after inflation adjustment

```{r, warning=FALSE, echo=FALSE, fig.width=8, fig.height=4, fig.cap="Monthly evolution of crude oil and Diesel & Gasoline prices after adjustment for inflation"}

p1 = ggplot(data4[data4$Type=="Diesel"|data4$Type=="Gasoline",])+
  aes(x=Date,y=Value,colour=Type)+
  geom_line()+
  ggtitle("Evolution of Retail Prices of Diesel and Gasoline",subtitle = "Adjusted for inflation")+
  xlab("Year")+
  ylab("Price in dolars (1994)")

p2 = ggplot(data4[data4$Type=="Crude",])+
  aes(x=Date,y=Value,colour=Type)+
  geom_line()+
  ggtitle("Crude Oil Prices",subtitle = "Adjusted for inflation")+
  xlab("Year")+
  ylab("Price in dolars (1994)")+
  geom_line(aes(y=rollmean(Value, 12, na.pad=TRUE)),colour="blue")

grid.arrange(p1,p2, ncol = 2)
```

## Check Seasonality [maybe we can replace that with my section (see section below)]

One important step in time series analysis is the checking of seasonality. In order to do that we will plot the average value of the series for each month (and then for each season).
The oil price series (bellow) has similar mean values for each month with a higher variability in summer months. But by the look of the plot there is a small chance that it would have a trend.
```{r}
data4<-data.frame(data4,month=as.numeric(format(as.Date(data4$Date, format="%d/%m/%Y"),"%m")))
ggplot(data4[data4$Type=="Crude",])+
  aes(x=as.factor(month),y=Value)+
  geom_boxplot()+
  stat_summary(fun=median, geom="smooth", aes(group=1))+
  ggtitle("Monthly oil prices",subtitle = "Adjusted for inflation")+
  xlab("Month")+
  ylab("Price in dolars (1994)")
```
The number of miles traveled data  does seem to have a monthly trend based on the values of the medians with a sharp decrease in the month of February. We will also try to plot the per season data.
```{r}
ggplot(data4[data4$Type=="Miles",])+
  aes(x=as.factor(month),y=Value)+
  geom_boxplot()+
  stat_summary(fun=median, geom="smooth", aes(group=1))+
  ggtitle("Monthly Miles Travelled")+
  xlab("Month")+
  ylab("Miles Travelled")
```

```{r}
for ( i in 1:nrow(data4)){
  if(data4$month[i] %in% c(12,1,2)){
  data4$season[i]<-"winter"
}
if (data4$month[i] %in% c(3,4,5)){
  data4$season[i]<-"spring"
}
if(data4$month[i] %in% c(6,7,8)){
  data4$season[i]<-"summer"
}
if (data4$month[i] %in% c(9,10,11)){
  data4$season[i]<-"autumn"
}
}

ggplot(data4[data4$Type=="Miles",])+
  aes(x=as.factor(season),y=Value)+
  geom_boxplot()+
  stat_summary(fun=median, geom="smooth", aes(group=1))+
  ggtitle("Monthly Miles Travelled")+
  xlab("Month")+
  ylab("Miles Travelled")
```

```{r}
RA_Miles<-rollmean(data3$Miles,12)
```

## Time Series decomposition and analysis

Time series decompostion is an essential step for the exploratory data analysis. It gives rich insight on the different elements of the series when it comes to trend, seasonality and the remainder. The time decomposition method that we chose is "STL" which stands for “Seasonal and Trend decomposition using Loess,” while Loess is a method for estimating nonlinear relationships. The following plot shows the time decomposition of the univariate time series "Crude oil" to better visualize how it works.

In this section, we will perform a time series decomposition of the crude oil and the miles times series to further explore them.

```{r, warnings = FALSE, fig.align='center', fig.width=12, fig.height=10, echo = FALSE}
df = data3 %>%
  mutate(Date = as.POSIXct(Date)) %>% 
  remove_rownames() %>% 
  as_tibble()

#-- Time series decomposition of Crude, Miles, Gasoline and Diesel
d1 = df %>% time_decompose(Crude, method = "stl", frequency = "auto", trend = "auto", message = FALSE)
d2 = df %>% time_decompose(Miles, method = "stl", frequency = "auto", trend = "auto", message = FALSE)
d3 = df %>% time_decompose(Gasoline, method = "stl", frequency = "auto", trend = "auto", message = FALSE)
d4 = df %>% time_decompose(Diesel, method = "stl", frequency = "auto", trend = "auto", message = FALSE)

#-- plots for only crude and miles time series and arrange in a grid
p1 = ggplot(d1, aes(x = Date, y = observed)) + 
  geom_line(color = "steelblue", size = 1) + theme_bw() + ggtitle("Raw data of Crude oil prices") + 
  scale_x_datetime(date_labels = "%Y", breaks = date_breaks("1 year"), labels=date_format('%Y')) + 
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

p2 = ggplot(d1, aes(x = Date, y = season)) +
  geom_line(color = "steelblue", size = 1) + theme_bw() + ggtitle("Seasonality") + 
  scale_x_datetime(date_labels = "%Y", breaks = date_breaks("1 year"), labels=date_format('%Y')) + 
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

p3 = ggplot(d1, aes(x = Date, y = trend)) +
  geom_line(color = "steelblue", size = 1) + theme_bw() + ggtitle("Trend") + 
  scale_x_datetime(date_labels = "%Y", breaks = date_breaks("1 year"), labels=date_format('%Y')) + 
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

#-- do plots and arrange in a grid
p4 = ggplot(d2, aes(x = Date, y = observed)) + 
  geom_line(color = "steelblue", size = 1) + theme_bw() + ggtitle("Raw data of Miles traveled") + 
  scale_x_datetime(date_labels = "%Y", breaks = date_breaks("1 year"), labels=date_format('%Y')) + 
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

p5 = ggplot(d2, aes(x = Date, y = season)) +
  geom_line(color = "steelblue", size = 1) + theme_bw() + ggtitle("Seasonality") + 
  scale_x_datetime(date_labels = "%Y", breaks = date_breaks("1 year"), labels=date_format('%Y')) + 
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

p6 = ggplot(d2, aes(x = Date, y = trend)) +
  geom_line(color = "steelblue", size = 1) + theme_bw() + ggtitle("Trend") + 
  scale_x_datetime(date_labels = "%Y", breaks = date_breaks("1 year"), labels=date_format('%Y')) + 
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

grid.arrange(p1,p4,p2,p5,p3,p6, nrow = 3, ncol = 2)
```

Upon examining the crude oil plots, we notice the unexistance of a linear trend, hence indicating non stationarity in the crude oil prices. In addition, we notice that the seasonal trend is slightly irregular throughout the year. The upper and lower bound of the seasonal component hints that it is statistically insignificant compared to the actual bounds of the crude oil prices.

The Miles times series, however, shows some more structure. The seasonality is non-negligable and a linear trend is visible. We can zoom in further on the seasonality effect of this variable by showing a box plot of the mean of all years of data throughout each month.

```{r, echo=FALSE, warning=FALSE, fig.width=6, fig.height=4, fig.cap="Seasonality of Miles"}
for ( i in 1:nrow(data4)){
  if(data4$month[i] %in% c(12,1,2)){
  data4$season[i]<-"winter"
}
if (data4$month[i] %in% c(3,4,5)){
  data4$season[i]<-"spring"
}
if(data4$month[i] %in% c(6,7,8)){
  data4$season[i]<-"summer"
}
if (data4$month[i] %in% c(9,10,11)){
  data4$season[i]<-"autumn"
}
}

to_plot<-aggregate(Value~Type+year+season,data=data4,mean)
to_plot$means<--1
to_plot$s_index<-0
season<-c("winter","spring","summer","autumn")
for (i in unique(to_plot$Type)){
  for (j in unique(season)){
    to_plot[to_plot$Type==i&to_plot$season==j,]$means<-mean(to_plot[to_plot$Type==i&to_plot$season==j,"Value"])
    to_plot[to_plot$Type==i&to_plot$season==j,]$s_index<-(max(to_plot[to_plot$Type==i,"s_index"])+1):(max(to_plot[to_plot$Type==i,"s_index"])+nrow(to_plot[to_plot$Type==i&to_plot$season==j,]))
  }
}
ggplot(to_plot[to_plot$Type=="Miles",])+
  aes(x=s_index,y=Value,colour=season)+
  geom_line(size = 1)+
  geom_line(aes(y=means,colour=season), size = 1.5)+
  ggtitle("Monthly Miles Travelled")+
  xlab("Month")+
  ylab("Miles Travelled") + theme_bw()
```

Indeed, we find that during winters, people are less likely to be traveling due to harsh weather conditions. In contrast, summers tend to be more active and we can see a clear increase of miles traveled in hotter periods.

## Checking for Autocorrelation

### Autocorrelation of the white noise process

One of the most important assumptions of any time series modeling is *random noise*. Therefore, we will explore the remainder component in order to make sure it satisfies the random noise assumptions which are the following :

* Little to no autocorrelation (i.e.  $\mathbb{E} (\varepsilon_t \times \varepsilon_\tau) = 0$ $\forall t,\tau \in \mathbb{Z}$ given that $ \tau \neq t$ )
* Normal distribution with $\mathbb{E} (\varepsilon_t) = 0$ and $\mathbb{E} (\varepsilon_t^2) = \sigma^2$

To check these assumptions, we will first plot the autocorrelation of all 4 variables of interest; Gasoline, Diesel, Miles and Crude which we can see in the figure below :

```{r, warnings = FALSE, fig.align='center', fig.width=7, fig.height=5, echo = FALSE, fig.cap="Autocorrelation of the white noise processes"}
library(forecast)

p1 = ggAcf(ts(d1$remainder)) + ggtitle("Autocorrelation of Crude") + theme_bw()
p2 = ggAcf(ts(d2$remainder)) + ggtitle("Autocorrelation of Miles") + theme_bw()
p3 = ggAcf(ts(d3$remainder)) + ggtitle("Autocorrelation of Gasoline") + theme_bw()
p4 = ggAcf(ts(d4$remainder)) + ggtitle("Autocorrelation of Diesel") + theme_bw()

grid.arrange(p1,p2,p3,p4)
```

We can clearly discern some structure in the beginning of the autocorrelation plots of the white noise processes for each of the time series at hand. This is an indicator of non stationarity that should be handled before proceeding to do any modeling.

### Autocorrelation of the covariates [maybe we can replace with this??]

Similarly, we will explore the autocorrelation of each of the covariates of interest as a function of the lag. Their corresponding plots below indicate a high autocorrelation with respect to their lagg, further confirming the non stationarity found in all of the covariates.

```{r, warnings = FALSE, fig.align='center', fig.width=6, fig.height=4, echo = FALSE, fig.cap="Autocorrelation of all the covariates"}
#-- loop over the covariates and create autocorrelation plots
p = list()
for (i in 2:ncol(data3)){
  p[[i]] = ggAcf(ts(data3[,i])) + 
    ggtitle(paste("Autocorrelation of", names(data3)[i])) + 
    theme(plot.title = element_text(size = 8, face = "bold", hjust = 0.5)) + 
    theme_bw()
}
grid.arrange(p[[2]], p[[3]], p[[4]], p[[5]])
```


```{r}
################## Maybe we can delete this ?? ###########
par(mfrow=c(2,2))
for (i in 2:ncol(data3)){
  acf(data3[,i],main=NA)
  title(colnames(data3)[i], line = 0.5)
}
acf(RA_Miles)
```

### Partial Autocorrelation

Maybe add some comments?

```{r, warnings = FALSE, fig.align='center', fig.width=6, fig.height=4, echo = FALSE, fig.cap="Autocorrelation of all the covariates"}
#-- loop over the covariates and create autocorrelation plots
p = list()
for (i in 2:ncol(data3)){
  p[[i]] = ggPacf(ts(data3[,i])) + 
    ggtitle(paste("PACF of", names(data3)[i])) + 
    theme(plot.title = element_text(size = 8, face = "bold", hjust = 0.5)) + 
    theme_bw()
}
grid.arrange(p[[2]], p[[3]], p[[4]], p[[5]])
```

### Augumented Dickey-Fuller Test

Can you comment this??

```{r}
for (i in 2:ncol(data3)){
  print(paste("Augmented Dickey-Fuller test for ",colnames(data3)[i]," data: "))
  print(adf.test(data3[,i],alternative="stationary",k=1))
  
}
print(paste("Augmented Dickey-Fuller test for RA_Miles data: "))
print(adf.test(RA_Miles,alternative="stationary",k=1))
```

### Removing Stationarity

Our conclusion from the exploratory data analysis indicates that the time series we are studying is, indeed, a non-stationary process. A non-stationary process, by definition contains a trend that has a mean growing around a fixed trend, which is constant and independent of time.

However, a non-stationary time series can be transformed into a stationary process by differencing (i.e. subtracting $X_{t-1}$ from $X_t$).
Therefore, in this section, we will procees by taking the difference : 

$$
X_t \rightarrow X_t - X_{t-1}
$$ 

After doing so, We plot the auto correlation again to make sure we removed the non-stationarity and get the following results:

```{r, warnings = FALSE, fig.align='center', fig.width=6, fig.height=4, echo = FALSE, fig.cap="Autocorrelation of all the covariates"}
#-- differentiate to remove non-stationnarity
data5<-data.frame(Date=1:319)
data5$Date<-data3$Date[-1]
data5<-data.frame(data5,apply(data3[,2:4],MARGIN = 2,FUN = diff))
RA_Miles_stat<-diff(RA_Miles)

#-- loop over the covariates and create autocorrelation plots
p = list()
for (i in 2:ncol(data5)){
  p[[i]] = ggAcf(ts(data5[,i])) + 
    ggtitle(paste("Autocorrelation of", names(data5)[i])) + 
    theme(plot.title = element_text(size = 8, face = "bold", hjust = 0.5)) + 
    theme_bw()
}

#-- final plot for the miles
p[[5]] = ggAcf(ts(RA_Miles_stat)) + 
    ggtitle(paste("Autocorrelation of Miles")) + 
    theme(plot.title = element_text(size = 8, face = "bold", hjust = 0.5)) + 
    theme_bw()

#-- arrange in a grid
grid.arrange(p[[2]], p[[3]], p[[4]], p[[5]])
```

After examining the autocorrelation plots for the second time after differentiating, we can see that we get, to certain extent, w nicer stationary time series that can now use to build our ARMA model in the next step.

## Fitting ARMA Models

### Diesel

```{r}
errors<-data.frame(AR=1,MA=1,ERR=1)
k<-1
for (i in 1:5){
  for(j in 1:5){
    model<-arma(data5$Diesel,lag=list(ar=c(i),ma=c(j)))
    errors[k,1]<-i
    errors[k,2]<-j
    errors[k,3]<-model$css
    k<-k+1
  }
}
```